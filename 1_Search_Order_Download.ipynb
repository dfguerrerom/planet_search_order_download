{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "\n",
    "import rasterio\n",
    "from time import sleep\n",
    "from rasterio import plot\n",
    "from shapely.geometry import MultiPolygon, shape, Point\n",
    "from shapely_geojson import dumps\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from planet import api\n",
    "from planet.api import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to use your own api keys and parameters, copy paste the `parameters.py.dist` file in the same folder and remove the `.dist` extention. You can then replace the string with your own keys. only the .dist will be pushed to the dist git rep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parameters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_thumb(metadata_df):\n",
    "    \"\"\" From the metadata dataframe, save the thumbnail\n",
    "    in the corresponding folder:\n",
    "    \n",
    "    Args:\n",
    "        metadata_df (pd.DataFrame)\n",
    "        \n",
    "    Return:\n",
    "        stores thumbnails in folder\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.auth = (PLANET_API_KEY, '')\n",
    "    auth = session.auth\n",
    "    \n",
    "    for index, row in metadata_df.iterrows():\n",
    "        url = row.thumbnail\n",
    "        date = row.date\n",
    "        item_type = row.item_type\n",
    "        cloud_cover = row.cloud_cover\n",
    "        id_ = row.id\n",
    "        sample_id = row.sample_id\n",
    "        \n",
    "        thumb_name = f'it{item_type}_cc{cloud_cover}_y{date.year}m{date.month}_{id_}.jpg'\n",
    "        \n",
    "        thumb_path = os.path.join(os.getcwd(),'thumbs', \n",
    "                                  str(sample_id), \n",
    "                                  str(date.year))\n",
    "        \n",
    "        Path(thumb_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        r = requests.get(url, auth=auth, stream=True)\n",
    "        if r.status_code == 200:\n",
    "            with open(os.path.join(thumb_path, thumb_name), 'wb') as f:\n",
    "                r.raw.decode_content = True\n",
    "                shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_request(aoi_geom, start_date, stop_date, cloud_cover=100):\n",
    "    \"\"\"build a data api search request for PS imagery.\n",
    "    \n",
    "    Args:\n",
    "        aoi_geom (geojson): \n",
    "        start_date (datetime.datetime)\n",
    "        stop_date (datetime.datetime)\n",
    "    \n",
    "    Returns:\n",
    "        Request\n",
    "    \"\"\"\n",
    "    \n",
    "    query = filters.and_filter(\n",
    "        filters.geom_filter(aoi_geom),\n",
    "        filters.range_filter('cloud_cover', lte=cloud_cover),\n",
    "        filters.date_range('acquired', gt=start_date),\n",
    "        filters.date_range('acquired', lt=stop_date)\n",
    "    )\n",
    "    \n",
    "    # Skipping REScene because is not orthorrectified and \n",
    "    # cannot be clipped.\n",
    "    \n",
    "    return filters.build_search_request(query, [\n",
    "        'PSScene3Band', \n",
    "        'PSScene4Band', \n",
    "        'PSOrthoTile',\n",
    "        'REOrthoTile',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the data api\n",
    "def search_data_api(request, client, limit=1000000):\n",
    "    \"\"\" Search items from a given request.\n",
    "    \n",
    "    \"\"\"\n",
    "    result = client.quick_search(request)\n",
    "    \n",
    "    # this returns a generator\n",
    "    return result.items_iter(limit=limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(id_name, request):\n",
    "    \"\"\" Get items using the request with the given parameters\n",
    "    \n",
    "    Args:\n",
    "        row (geopandas.DataFrame.row): \n",
    "            gpd.df.row with two columns: id(index) and geometry\n",
    "        \n",
    "        start_date:\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    items = list(search_data_api(request, client))\n",
    "    \n",
    "    return [id_name, items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(items):\n",
    "    \n",
    "    items_metadata = [(f['properties']['acquired'],\n",
    "                     f['id'], \n",
    "                     f['properties']['item_type'],\n",
    "                     f['_links']['thumbnail'],\n",
    "                     f['_permissions'],\n",
    "                     f['geometry'],\n",
    "                     f['properties']['cloud_cover'],\n",
    "                     f\n",
    "                    ) for f in items[1]]\n",
    "    \n",
    "    # Store into dataframe\n",
    "    df = pd.DataFrame(items_metadata)\n",
    "    df[0] = pd.to_datetime(df[0])\n",
    "    df.columns=[\n",
    "        'date', \n",
    "        'id', \n",
    "        'item_type', \n",
    "        'thumbnail', \n",
    "        'permissions', \n",
    "        'footprint', \n",
    "        'cloud_cover', \n",
    "        'metadata'\n",
    "    ]\n",
    "    df['sample_id'] = items[0]\n",
    "    df.sort_values(by=['date'], inplace=True)\n",
    "    df.reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cover_area(metadata_df, sample_df):\n",
    "    \n",
    "    for idx, row in metadata_df.iterrows():\n",
    "        \n",
    "        g1 = sample_df.at[row.sample_id, 'geometry'] # sample geometry\n",
    "        g2 = shape(row.footprint) # footprint geometry\n",
    "        metadata_df.at[idx, 'cover_perc'] = (g1.intersection(g2).area/g1.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_order_from_metadata(metadata_df, samples_df, sample_id):\n",
    "    \n",
    "    filtered_df = metadata_df[metadata_df.sample_id==sample_id]\n",
    "    \n",
    "    items_by_type = [(item_type, filtered_df[filtered_df.item_type == item_type].id.to_list())\n",
    "              for item_type in filtered_df.item_type.unique()]\n",
    "    \n",
    "    products_bundles = {\n",
    "        \n",
    "        # Is not possible to ask for analytic_dn in PSScene3Band, so the next option is visual\n",
    "        # for more info go to https://developers.planet.com/docs/orders/product-bundles-reference/\n",
    "        'PSScene3Band': \"analytic,visual\",\n",
    "        'PSScene4Band': \"analytic_udm2,analytic_sr,analytic\",\n",
    "        'PSOrthoTile': \"analytic_5b_udm2,analytic_5b,analytic_udm2,analytic\",\n",
    "        'REOrthoTile': \"analytic\",\n",
    "    }\n",
    "\n",
    "    products_order = [\n",
    "        {\n",
    "            \"item_ids\":v, \n",
    "            \"item_type\":k, \n",
    "            \"product_bundle\": products_bundles[k]\n",
    "        } for k, v in items_by_type\n",
    "    ]\n",
    "    \n",
    "    # clip to AOI\n",
    "    aoi_geojson = json.loads(dumps(samples_df.at[sample_id, 'geometry']))\n",
    "    tools = [{\n",
    "        'clip': {\n",
    "            'aoi': aoi_geojson\n",
    "        }\n",
    "    },]\n",
    "    \n",
    "    order_request = {\n",
    "        'name': f'sample_{str(sample_id)}',\n",
    "        'products': products_order,\n",
    "        'tools': tools,\n",
    "        'delivery': {\n",
    "            'single_archive': True,\n",
    "            'archive_filename':'{{name}}_{{order_id}}.zip',\n",
    "            'archive_type':'zip'\n",
    "        },\n",
    "            'notifications': {\n",
    "                       'email': False\n",
    "        },\n",
    "    }\n",
    "    return order_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_items(dataframe, *args):\n",
    "    \"\"\"Filter and score each item according to the season and item_type\n",
    "    \n",
    "    Return:\n",
    "        Scored items dataframe.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Create a copy to avoid mutate the initial df\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    item_count_per_year = dict(df.groupby(df.date.dt.year).size())\n",
    "    \n",
    "    for k_year in item_count_per_year.keys():\n",
    "        \n",
    "        # Filter only years with more than one image\n",
    "        if item_count_per_year[k_year] > 1:\n",
    "\n",
    "            for idx, row in metadata_df.iterrows():\n",
    "                \n",
    "                month = row.date.month\n",
    "\n",
    "                df.at[idx, 'season_score'] = months_score[month]\n",
    "                df.at[idx, 'item_score'] = item_type_score[row['item_type']]\n",
    "                df.at[idx, 'cloud_score'] = cloud_score(row['cloud_cover'])\n",
    "                df.at[idx, 'covered_area'] = cover_score(row['cover_perc'])\n",
    "    \n",
    "    df['total_score'] = df.season_score + \\\n",
    "                        df.item_score + \\\n",
    "                        df.cloud_score + \\\n",
    "                        df.covered_area\n",
    "    \n",
    "    df = df.sort_values(by=['total_score', 'date'], ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_item_per_year(scored_items_df):\n",
    "    \n",
    "    df = scored_items_df.copy()\n",
    "    df['year'] = df.date.dt.year\n",
    "    df = df.drop_duplicates(subset=['year'], keep='first')\n",
    "    df = df.sort_values(by=['date'], ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_order(order_id, client, num_loops=50):\n",
    "    count = 0\n",
    "    while(count < num_loops):\n",
    "        count += 1\n",
    "        order_info = client.get_individual_order(order_id).get()\n",
    "        state = order_info['state']\n",
    "        print(state)\n",
    "        success_states = ['success', 'partial']\n",
    "        if state == 'failed':\n",
    "            raise Exception(response)\n",
    "        elif state in success_states:\n",
    "            break\n",
    "        \n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Search items\n",
    "### Get the samples dataframe\n",
    "\n",
    "From a geojson plots file, create a geo pandas dataframe to store the geometries and the id of each plot, it'll be used as a geometry filter and to calculate the % of area covered by the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_gdf = pd.read_pickle('shp/samples.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = api.ClientV1(api_key=PLANET_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test data for the filter\n",
    "start_date = datetime.datetime(2009, 1, 1)\n",
    "stop_date = datetime.datetime(2020, 12, 31)\n",
    "cloud_cover_lte = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_type_score\n",
    "item_type_score = {\n",
    "    'PSScene4Band':8, \n",
    "    'PSScene3Band':8, \n",
    "    'PSOrthoTile':10,\n",
    "    'REOrthoTile':0,\n",
    "    'SkySatScene':0,\n",
    "}\n",
    "\n",
    "# season score\n",
    "months_score = {\n",
    "    1: 5, 7:0,\n",
    "    2: 5, 8:0,\n",
    "    3: 5, 9:0,\n",
    "    4: 0, 10:7,\n",
    "    5: 0, 11:10,\n",
    "    6: 0, 12:10,\n",
    "}\n",
    "\n",
    "# cloud_score\n",
    "\n",
    "def cloud_score(cloud_cover):\n",
    "    \"\"\" Define the cloud cover threshold and score\n",
    "    \"\"\"\n",
    "    cloud_cover = cloud_cover*100\n",
    "    \n",
    "    if cloud_cover == 0:\n",
    "        return 10\n",
    "    elif cloud_cover <= 1 and cloud_cover > 0:\n",
    "        return 5\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# Covered area\n",
    "\n",
    "def cover_score(covered_area):\n",
    "    \"\"\"Define the cover area threshold and score\n",
    "    \"\"\"\n",
    "    covered_area = covered_area*100\n",
    "    \n",
    "    if covered_area >= 99:\n",
    "        return 10\n",
    "    \n",
    "    elif covered_area >= 95:\n",
    "        return 5\n",
    "    \n",
    "    elif covered_area >= 90:\n",
    "        return 0\n",
    "    \n",
    "minimum_covered_area = 90 # included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION: 1.1 Get items for individual samples ((optional))\n",
    "### Get items and metadata using filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AOI, by selecting the first row of the samples geodataframe\n",
    "# For this example, we are going to use the first sample\n",
    "row_number = 0\n",
    "aoi_geometry = json.loads(dumps(samples_gdf.iloc[row_number].geometry))\n",
    "sample_id = samples_gdf.iloc[row_number].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "request = build_request(aoi_geometry, start_date, stop_date, cloud_cover_lte)\n",
    "items = get_items(sample_id, request)\n",
    "\n",
    "# Transform items into a pandas dataframe with useful columns\n",
    "metadata_df = get_dataframe(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate percentage of covered area\n",
    "\n",
    "Calculate the percentage of covered area from the sample area with the item footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutate metadata_df and add the percentage of cover area\n",
    "add_cover_area(metadata_df, samples_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove items that are under 90% of covered area\n",
    "metadata_df = metadata_df[metadata_df.cover_perc >= minimum_covered_area]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_items = score_items(metadata_df, item_type_score, months_score, cloud_score, cover_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_items = get_one_item_per_year(scored_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ((Optional)): Export thumbnails\n",
    "Create thumbnails from the selected items (dataframe) and store them into a structured folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_thumb(selected_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTION 1.2 Get items for all plots and store into a big df\n",
    "### Loop over all plots\n",
    "Loop over all plots and get the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dataframes \n",
    "\n",
    "df_list = []\n",
    "pbar = tqdm(total = len(samples_gdf))\n",
    "for index, row in samples_gdf.iterrows():\n",
    "    \n",
    "    aoi_geometry = json.loads(dumps(row.geometry))\n",
    "    sample_id = row.name\n",
    "    \n",
    "    request = build_request(aoi_geometry, start_date, stop_date, cloud_cover_lte)\n",
    "    items = get_items(sample_id, request)\n",
    "    \n",
    "    # Transform items into a pandas dataframe with useful columns\n",
    "    metadata_df = get_dataframe(items)\n",
    "    \n",
    "    # Mutate metadata_df and add the percentage of cover area\n",
    "    add_cover_area(metadata_df, samples_gdf)\n",
    "    \n",
    "    # Remove items that are under the minimum_covered_area threshold\n",
    "    metadata_df = metadata_df[metadata_df.cover_perc >= minimum_covered_area]\n",
    "    \n",
    "    # Create a score for each item\n",
    "    scored_items = score_items(metadata_df, item_type_score, months_score, cloud_score)\n",
    "    \n",
    "    # Filter scored_items and get only one per year\n",
    "    selected_items = get_one_item_per_year(scored_items)\n",
    "    \n",
    "    # Append selected_items to a list\n",
    "    df_list.append(selected_items)\n",
    "    \n",
    "    del metadata_df, scored_items, selected_items\n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes from the df_list\n",
    "all_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Order assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the order we need a dataframe with filtered items,\n",
    "# and a samples_gdf with sample_id and geometry to clip each item.\n",
    "\n",
    "# Build an order for each sample and store in a orders_list\n",
    "orders = []\n",
    "for idx, row in samples_gdf.iterrows():\n",
    "    order = build_order_from_metadata(all_df, samples_gdf, sample_id=idx)\n",
    "    orders.append(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request order\n",
    "<font color='red'>The following lines will start the order in the planet server, after the order is created and is running, there is no way to stop it.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request orders and store its sample_id (name)\n",
    "orders = client.get_orders().get()\n",
    "ordered_sample_ids = [o['name'] for o in orders['orders']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_info = []\n",
    "for new_order in orders:\n",
    "    \n",
    "    # Make sure that the sample is not already downloaded\n",
    "    if new_order not in ordered_sample_ids:\n",
    "        order_info = client.create_order(new_order).get()\n",
    "        \n",
    "        orders_info.append(order_info)\n",
    "        order_id = order_info['id']\n",
    "        sample_name = order_info['name']\n",
    "        print(f'order {order_id} with {sample_name} has been placed')\n",
    "        \n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = client.get_orders().get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_id = order_info['id']\n",
    "order_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_order(order_id, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = os.path.join(os.getcwd(),'downloads')\n",
    "\n",
    "# Define the dates in which the desired oreders were ordered.\n",
    "\n",
    "start_date = datetime.date(2020,9,8)\n",
    "stop_date = datetime.date(2020,9,8)\n",
    "\n",
    "for order in orders['orders']:\n",
    "    \n",
    "    created_on = pd.to_datetime(order['created_on']).date()\n",
    "\n",
    "    if created_on >= start_date and created_on <= stop_date:\n",
    "        \n",
    "        # Create the download folder\n",
    "        download_order_path = os.path.join(download_path, order['name'])\n",
    "        Path(download_order_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        callback = api.write_to_file(directory=f'{download_order_path}/', overwrite=True)\n",
    "        locations = client.download_order(order['id'], callback=callback)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
